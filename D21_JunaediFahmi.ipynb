{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D21_JunaediFahmi.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juunnn/DTSAI2019/blob/master/D21_JunaediFahmi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1ctRDnkdQeM",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDL2UDLMmh5I",
        "colab_type": "text"
      },
      "source": [
        "## Step by step CNN by Andrew Ng\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a2X-uGidMGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5ABQcS7sQ6v",
        "colab_type": "text"
      },
      "source": [
        "### 1. Define padding to image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYRa0R_tqLfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: zero_pad\n",
        "\n",
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "    as illustrated in Figure 1.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (â‰ˆ 1 line)\n",
        "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f74boCmMqTws",
        "colab_type": "code",
        "outputId": "c081bed2-cb2f-471c-b809-79b4b49b03b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4,3,3,2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print(\"x.shape:\",x.shape)\n",
        "print(\"x_pad.shape:\", x_pad.shape)\n",
        "print(\"x[1,1]:\", x[1,1])\n",
        "print(\"x_pad[1,1]\",x_pad[1,1])\n",
        "\n",
        "fig, axarr = plt.subplots(1,2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (4, 3, 3, 2)\n",
            "x_pad.shape: (4, 7, 7, 2)\n",
            "x[1,1]: [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f01b89e7358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAACuCAYAAABUfpQYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GehfvMCvr6yZ",
        "colab_type": "text"
      },
      "source": [
        "### 2. Define Convolution on Single Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YHCIoz3rbTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    s = np.multiply(a_slice_prev, W) + b\n",
        "    Z = np.sum(s)\n",
        "\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vTiD-6qrz5J",
        "colab_type": "code",
        "outputId": "b56cb426-c06c-428d-aeae-9ae968873158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z = -23.16021220252078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odZyEElasZxV",
        "colab_type": "text"
      },
      "source": [
        "### 3. Define Convolution Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om4VyXDAsecP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_forward(A_prev, W, b, hparams):\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "    (f,f,n_C_prev, n_C) = W.shape\n",
        "\n",
        "    stride = hparams['stride']\n",
        "    pad = hparams['pad']\n",
        "\n",
        "    n_H = int( (n_H_prev - f + 2*pad) / stride) + 1\n",
        "    n_W = int( (n_W_prev - f + 2*pad) / stride) + 1\n",
        "\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "\n",
        "    for i in range(m):\n",
        "        a_prev_pad = A_prev_pad[1]\n",
        "        for h in range(n_H):\n",
        "            for w in range(n_W):\n",
        "                for c in range(n_C):\n",
        "                    v_start = h * stride\n",
        "                    v_end = v_start + f\n",
        "                    h_start = w * stride\n",
        "                    h_end = h_start + f\n",
        "                    \n",
        "                    a_slice_prev = a_prev_pad[v_start:v_end, h_start:h_end,:]\n",
        "\n",
        "                    Z[i,h,w,c] = conv_single_step(a_slice_prev, W[...,c], b[...,c])\n",
        "\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "\n",
        "    cache = (A_prev,W, b, hparams)\n",
        "\n",
        "    return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avZxv5edvkg-",
        "colab_type": "code",
        "outputId": "0a01bda8-9e45-41d2-8986-ee971854d7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10, 4, 4, 3)\n",
        "W = np.random.randn(2, 2, 3, 8)\n",
        "b = np.random.randn(1, 1, 1, 8)\n",
        "hparameters = {\"pad\" : 2,\n",
        "               \"stride\": 1}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\", np.mean(Z))\n",
        "print(\"Z[1][2][3]\", Z[1,2,3])\n",
        "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z's mean = 0.10259422788382341\n",
            "Z[1][2][3] [  3.97577197  -2.90234252  -1.18706955  17.00859655   8.22302755\n",
            "   3.85652638 -11.20450403   2.16979357]\n",
            "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L7zD5DJto2E",
        "colab_type": "text"
      },
      "source": [
        "### 4. Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_6AEX3nv39W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool_forward(A_prev, hparams, mode=\"max\"):\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    f = hparams['f']\n",
        "    stride = hparams['stride']\n",
        "\n",
        "    n_H = int(1+ (n_H_prev - f)/stride)\n",
        "    n_W = int(1 + (n_W_prev - f)/stride)\n",
        "    n_C = n_C_prev\n",
        "\n",
        "    A = np.zeros((m,n_H, n_W,n_C))\n",
        "    for i in range(m):\n",
        "        for h in range(n_H):\n",
        "            for w in range(n_W):\n",
        "                for c in range(n_C):\n",
        "                    v_start = h*stride\n",
        "                    v_end = v_start + f\n",
        "                    h_start = w*stride\n",
        "                    h_end = h_start + f\n",
        "\n",
        "                    a_prev_slice = A_prev[i, v_start:v_end, h_start:h_end,c]\n",
        "\n",
        "                    if mode == \"max\":\n",
        "                        A[i,h,w,c] = np.max(a_prev_slice)\n",
        "                    elif mode==\"average\":\n",
        "                        A[i,h,w,c] = np.mean(a_prev_slice)\n",
        "\n",
        "    assert(A.shape == (m,n_H, n_W, n_C))\n",
        "\n",
        "    cache = (A_prev, hparams)\n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXMfHxugwVEr",
        "colab_type": "code",
        "outputId": "9add849d-4d93-47b8-de2c-2201411959ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 4, 4, 3)\n",
        "hparameters = {\"stride\" : 1, \"f\": 4}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A =\", A)\n",
        "print()\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A =\", A)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "A = [[[[1.74481176 1.6924546  2.10025514]]]\n",
            "\n",
            "\n",
            " [[[1.19891788 1.51981682 2.18557541]]]]\n",
            "\n",
            "mode = average\n",
            "A = [[[[-0.09498456  0.11180064 -0.14263511]]]\n",
            "\n",
            "\n",
            " [[[-0.09525108  0.28325018  0.33035185]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEaH3o_qyttu",
        "colab_type": "text"
      },
      "source": [
        "### 5. Backprop Conv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zadk7oJYysTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_backward(dZ, cache):\n",
        "    (A_prev, W, b, hparams) = cache\n",
        "\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "\n",
        "    stride = hparams['stride']\n",
        "    pad = hparams['pad']\n",
        "\n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "    dA_prev = np.zeros((m,n_H_prev,n_W_prev, n_C_prev))\n",
        "    dW = np.zeros((f,f,n_C_prev,n_C))\n",
        "    db = np.zeros((1,1,1,n_C))\n",
        "\n",
        "    A_prev_pad = zero_pad(A_prev,pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "\n",
        "    for i in range(m):\n",
        "        a_prev_pad = A_prev_pad[i]\n",
        "        da_prev_pad = dA_prev_pad[i]\n",
        "\n",
        "        for h in range(n_H):\n",
        "            for w in range(n_W):\n",
        "                for c in range(n_C):\n",
        "                    v_start = h * stride\n",
        "                    v_end = v_start + f\n",
        "                    h_start = w * stride\n",
        "                    h_end = h_start + f\n",
        "\n",
        "                    a_slice = a_prev_pad[v_start:v_end, h_start:h_end,:]\n",
        "\n",
        "                    da_prev_pad[v_start:v_end, h_start:h_end,:] += W[:,:,:,c] * dZ[i,h,w,c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i,h,w,c]\n",
        "                    db[:,:,:,c] += dZ[i,h,w,c]\n",
        "        dA_prev[i,:,:,:] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
        "    assert(dA_prev.shape == (m,n_H_prev, n_W_prev, n_C_prev))\n",
        "\n",
        "    return dA_prev, dW, db\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohExyXvj2-2b",
        "colab_type": "code",
        "outputId": "88226430-772e-493c-d0b7-282f10213608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "dA, dW, db = conv_backward(Z, cache_conv)\n",
        "print(\"dA_mean =\", np.mean(dA))\n",
        "print(\"dW_mean =\", np.mean(dW))\n",
        "print(\"db_mean =\", np.mean(db))\n",
        "print(dA.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dA_mean = 18.40098308643454\n",
            "dW_mean = 1.9595907051782742\n",
            "db_mean = 50.27117166306732\n",
            "(10, 4, 4, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIXuP8AU3TDp",
        "colab_type": "text"
      },
      "source": [
        "#### Create Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLwloVl_3W6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask_from_window(x):\n",
        "    mask = x == np.max(x)\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvCDWymW3jHU",
        "colab_type": "code",
        "outputId": "f197b9ca-edd5-4410-ab32-7d7bfc1fe662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(2,3)\n",
        "mask = create_mask_from_window(x)\n",
        "print('x = ', x)\n",
        "print(\"mask = \", mask)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
            " [-1.07296862  0.86540763 -2.3015387 ]]\n",
            "mask =  [[ True False False]\n",
            " [False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIoj5mX63olB",
        "colab_type": "text"
      },
      "source": [
        "#### Distribute Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvxkUgtH3usV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distribute_value(dZ, shape):\n",
        "    (n_H, n_W) = shape\n",
        "    average = dZ / (n_H * n_W)\n",
        "\n",
        "    a = np.ones(shape) * average\n",
        "\n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp3kFG6b4B20",
        "colab_type": "code",
        "outputId": "6c0eef2e-2580-458e-bd41-e94b9068bf0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = distribute_value(2, (2,2))\n",
        "print('distributed value =', a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distributed value = [[0.5 0.5]\n",
            " [0.5 0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUyucex24YQl",
        "colab_type": "text"
      },
      "source": [
        "#### Pooling Backwards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8bPIrLi4dcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool_backward(dA, cache, mode=\"max\"):\n",
        "    (A_prev, hparams) = cache\n",
        "\n",
        "    stride = hparams['stride']\n",
        "    f = hparams['f']\n",
        "    \n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    m, n_H, n_W, n_C = dA.shape\n",
        "\n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "\n",
        "    for i in range(m):\n",
        "        a_prev = A_prev[i]\n",
        "        for h in range(n_H):\n",
        "            for w in range(n_W):\n",
        "                for c in range(n_C):\n",
        "                    v_start = h\n",
        "                    v_end = v_start + f\n",
        "                    h_start = w\n",
        "                    h_end = h_start + f\n",
        "\n",
        "                    if mode == 'max':\n",
        "                        a_prev_slice = a_prev[v_start:v_end, h_start:h_end, c]\n",
        "                        mask = create_mask_from_window(a_prev_slice)\n",
        "                        dA_prev[i,v_start:v_end, h_start:h_end, c] += np.multiply(mask, dA[i,h,w,c])\n",
        "                    elif mode == 'average':\n",
        "                        da = dA[i,h,w,c]\n",
        "                        shape = (f,f)\n",
        "\n",
        "                        dA_prev[i,v_start:v_end, h_start:h_end, c] = distribute_value(da, shape)\n",
        "\n",
        "    assert(dA_prev.shape == A_prev.shape)\n",
        "\n",
        "    return dA_prev\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xU64IPt620k",
        "colab_type": "code",
        "outputId": "dea43241-a20b-4d45-ac45-b321aea9734a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(5, 5, 3, 2)\n",
        "hparameters = {\"stride\" : 1, \"f\": 2}\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "dA = np.random.randn(5, 4, 2, 2)\n",
        "\n",
        "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
        "print(\"mode = max\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
        "print()\n",
        "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print('mean of dA = ', np.mean(dA))\n",
        "print('dA_prev[1,1] = ', dA_prev[1,1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mode = max\n",
            "mean of dA =  0.14571390272918056\n",
            "dA_prev[1,1] =  [[ 0.          0.        ]\n",
            " [ 5.05844394 -1.68282702]\n",
            " [ 0.          0.        ]]\n",
            "\n",
            "mode = average\n",
            "mean of dA =  0.14571390272918056\n",
            "dA_prev[1,1] =  [[-0.16172917  0.22537172]\n",
            " [ 0.63208143 -0.06215869]\n",
            " [ 0.63208143 -0.06215869]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ez-buxL7HFo",
        "colab_type": "text"
      },
      "source": [
        "## CNN with KERAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPRJ4fN-MO6H",
        "colab_type": "text"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eaVA4UG7jnx",
        "colab_type": "code",
        "outputId": "8e61185d-f839-42c8-d928-4d517c3910b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3o-mgOlMU8J",
        "colab_type": "text"
      },
      "source": [
        "### Copy necessery files to current directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVxYxak_8ASc",
        "colab_type": "code",
        "outputId": "a3d3c8d5-4c3f-45f4-b8f7-85f237ab1589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!cp /gdrive/My\\ Drive/Day\\ 21/datasets -r .\n",
        "!cp /gdrive/My\\ Drive/Day\\ 21/kt_utils.py .\n",
        "!python kt_utils.py\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTwt4o-XMfjl",
        "colab_type": "text"
      },
      "source": [
        "### Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpxxW36L81B2",
        "colab_type": "code",
        "outputId": "95def0d0-540f-4e13-d3d7-2cb62b1e1ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from kt_utils import *\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://b71a5e74.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iab1JKYOMi6i",
        "colab_type": "text"
      },
      "source": [
        "### Load dataset and spliting totrain and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhEYarEA8_8M",
        "colab_type": "code",
        "outputId": "5cb1d56b-b621-49b4-8427-e79d768efe19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Reshape\n",
        "Y_train = Y_train_orig.T\n",
        "Y_test = Y_test_orig.T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 600\n",
            "number of test examples = 150\n",
            "X_train shape: (600, 64, 64, 3)\n",
            "Y_train shape: (600, 1)\n",
            "X_test shape: (150, 64, 64, 3)\n",
            "Y_test shape: (150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2bIPBIHMsoH",
        "colab_type": "text"
      },
      "source": [
        "### Definisikan model umum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o08F8wUC9Cdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_shape):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding: pads the border of X_input with zeroes\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
        "\n",
        "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
        "\n",
        "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
        "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwQ1nXnNMxkv",
        "colab_type": "text"
      },
      "source": [
        "### Train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB9JnBKKBn-0",
        "colab_type": "code",
        "outputId": "fa73341a-758b-4c7a-c89d-64f9f65d134e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_1 = model(X_train.shape[1:])\n",
        "model_1.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "model_1.fit(X_train, Y_train, epochs=40, batch_size=50, callbacks=[TensorBoardColabCallback(tbc)])\n",
        "preds = model_1.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
        "\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 04:51:26.922293 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 04:51:26.956733 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 04:51:26.975056 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0730 04:51:27.022021 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0730 04:51:27.023692 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0730 04:51:27.306328 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0730 04:51:27.387825 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0730 04:51:27.414052 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 04:51:27.441341 139646030858112 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0730 04:51:30.104358 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0730 04:51:30.216356 139646030858112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "600/600 [==============================] - 6s 9ms/step - loss: 1.4297 - acc: 0.6233\n",
            "Epoch 2/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.4308 - acc: 0.8217\n",
            "Epoch 3/40\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.2536 - acc: 0.9017\n",
            "Epoch 4/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1473 - acc: 0.9483\n",
            "Epoch 5/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1210 - acc: 0.9533\n",
            "Epoch 6/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1057 - acc: 0.9700\n",
            "Epoch 7/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1073 - acc: 0.9667\n",
            "Epoch 8/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0945 - acc: 0.9683\n",
            "Epoch 9/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0692 - acc: 0.9850\n",
            "Epoch 10/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0528 - acc: 0.9833\n",
            "Epoch 11/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0506 - acc: 0.9900\n",
            "Epoch 12/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0461 - acc: 0.9867\n",
            "Epoch 13/40\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.0567 - acc: 0.9833\n",
            "Epoch 14/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0541 - acc: 0.9833\n",
            "Epoch 15/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0768 - acc: 0.9700\n",
            "Epoch 16/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0566 - acc: 0.9833\n",
            "Epoch 17/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0458 - acc: 0.9833\n",
            "Epoch 18/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0418 - acc: 0.9883\n",
            "Epoch 19/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0334 - acc: 0.9950\n",
            "Epoch 20/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0276 - acc: 0.9950\n",
            "Epoch 21/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0220 - acc: 0.9950\n",
            "Epoch 22/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0231 - acc: 0.9933\n",
            "Epoch 23/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0203 - acc: 0.9950\n",
            "Epoch 24/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0334 - acc: 0.9850\n",
            "Epoch 25/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0331 - acc: 0.9867\n",
            "Epoch 26/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0222 - acc: 0.9983\n",
            "Epoch 27/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0149 - acc: 0.9983\n",
            "Epoch 28/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0145 - acc: 0.9967\n",
            "Epoch 29/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0173 - acc: 0.9950\n",
            "Epoch 30/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0136 - acc: 0.9967\n",
            "Epoch 31/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0110 - acc: 0.9967\n",
            "Epoch 32/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0122 - acc: 0.9967\n",
            "Epoch 33/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0096 - acc: 0.9983\n",
            "Epoch 34/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0092 - acc: 0.9983\n",
            "Epoch 35/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0112 - acc: 0.9967\n",
            "Epoch 36/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0128 - acc: 0.9967\n",
            "Epoch 37/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0145 - acc: 0.9950\n",
            "Epoch 38/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0109 - acc: 0.9983\n",
            "Epoch 39/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0106 - acc: 0.9967\n",
            "Epoch 40/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0086 - acc: 0.9983\n",
            "150/150 [==============================] - 1s 3ms/step\n",
            "\n",
            "Loss = 0.06695165395736695\n",
            "Test Accuracy = 0.9666666706403096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzjXSfZDM17L",
        "colab_type": "text"
      },
      "source": [
        "### Definisikan model happy HOuse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reyTO9Qo9jx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HappyModel(input_shape):\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
        "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
        "\n",
        "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
        "\n",
        "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
        "    model = Model(inputs=X_input, outputs=X, name='HappyModel')\n",
        "\n",
        "    return model    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfsqoe4o9r6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "happyModel = HappyModel(X_train.shape[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWlbYySE9tOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "happyModel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl_VunI8-Smz",
        "colab_type": "code",
        "outputId": "78af09e8-af0a-4dc7-e24a-cee6ee44fa71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "happyModel.fit(X_train, Y_train, epochs=40, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.1453 - acc: 0.5567\n",
            "Epoch 2/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.3523 - acc: 0.8267\n",
            "Epoch 3/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1834 - acc: 0.9400\n",
            "Epoch 4/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1494 - acc: 0.9417\n",
            "Epoch 5/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1286 - acc: 0.9550\n",
            "Epoch 6/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0794 - acc: 0.9833\n",
            "Epoch 7/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0844 - acc: 0.9767\n",
            "Epoch 8/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0636 - acc: 0.9817\n",
            "Epoch 9/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0604 - acc: 0.9850\n",
            "Epoch 10/40\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.0571 - acc: 0.9783\n",
            "Epoch 11/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0501 - acc: 0.9850\n",
            "Epoch 12/40\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.0464 - acc: 0.9850\n",
            "Epoch 13/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0463 - acc: 0.9850\n",
            "Epoch 14/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0443 - acc: 0.9883\n",
            "Epoch 15/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0421 - acc: 0.9850\n",
            "Epoch 16/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0347 - acc: 0.9933\n",
            "Epoch 17/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0261 - acc: 0.9950\n",
            "Epoch 18/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0260 - acc: 0.9950\n",
            "Epoch 19/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0222 - acc: 0.9950\n",
            "Epoch 20/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0238 - acc: 0.9967\n",
            "Epoch 21/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0272 - acc: 0.9950\n",
            "Epoch 22/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0275 - acc: 0.9917\n",
            "Epoch 23/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0211 - acc: 0.9967\n",
            "Epoch 24/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0210 - acc: 0.9950\n",
            "Epoch 25/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0445 - acc: 0.9833\n",
            "Epoch 26/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0257 - acc: 0.9933\n",
            "Epoch 27/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0224 - acc: 0.9950\n",
            "Epoch 28/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0151 - acc: 0.9967\n",
            "Epoch 29/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0134 - acc: 0.9983\n",
            "Epoch 30/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0111 - acc: 0.9983\n",
            "Epoch 31/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0221 - acc: 0.9950\n",
            "Epoch 32/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0161 - acc: 0.9967\n",
            "Epoch 33/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0162 - acc: 0.9983\n",
            "Epoch 34/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0183 - acc: 0.9967\n",
            "Epoch 35/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0192 - acc: 0.9950\n",
            "Epoch 36/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0147 - acc: 0.9933\n",
            "Epoch 37/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0116 - acc: 0.9983\n",
            "Epoch 38/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0113 - acc: 0.9967\n",
            "Epoch 39/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0099 - acc: 0.9967\n",
            "Epoch 40/40\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0096 - acc: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0190dd90b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Fm2y7L9zvR",
        "colab_type": "code",
        "outputId": "def3556c-eb4e-4e64-a3f5-846e71ba01ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "preds = happyModel.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
        "\n",
        "print()\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 1s 4ms/step\n",
            "\n",
            "Loss = 0.07011157194773356\n",
            "Test Accuracy = 0.9733333373069764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYbfjeX3QT5g",
        "colab_type": "code",
        "outputId": "3aac2628-ed74-473e-e0b4-feb0bad85cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget https://pm1.narvii.com/6848/8d46372e7ea193940e0f1b4e7c3203996ef9af58v2_hq.jpg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-30 05:03:36--  https://pm1.narvii.com/6848/8d46372e7ea193940e0f1b4e7c3203996ef9af58v2_hq.jpg\n",
            "Resolving pm1.narvii.com (pm1.narvii.com)... 13.32.80.11, 13.32.80.8, 13.32.80.33, ...\n",
            "Connecting to pm1.narvii.com (pm1.narvii.com)|13.32.80.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71036 (69K) [image/jpeg]\n",
            "Saving to: â€˜8d46372e7ea193940e0f1b4e7c3203996ef9af58v2_hq.jpgâ€™\n",
            "\n",
            "8d46372e7ea193940e0 100%[===================>]  69.37K   425KB/s    in 0.2s    \n",
            "\n",
            "2019-07-30 05:03:36 (425 KB/s) - â€˜8d46372e7ea193940e0f1b4e7c3203996ef9af58v2_hq.jpgâ€™ saved [71036/71036]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ROUZEDFn7Q",
        "colab_type": "code",
        "outputId": "a62d92b8-4518-48dd-aaf9-ddbf95f89a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "img_path = '8d46372e7ea193940e0f1b4e7c3203996ef9af58v2_hq.jpg'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "imshow(img)\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "print(happyModel.predict(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY_VPfS1Q8Ob",
        "colab_type": "code",
        "outputId": "011159f7-53b2-4099-a250-1da1e44d661c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "happyModel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 70, 70, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
            "_________________________________________________________________\n",
            "bn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "fc (Dense)                   (None, 1)                 32769     \n",
            "=================================================================\n",
            "Total params: 37,633\n",
            "Trainable params: 37,569\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4woM8_jRCYa",
        "colab_type": "code",
        "outputId": "a2b7b693-0fdd-4044-cf28-75dd9845ed9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "plot_model(happyModel, to_file='HappyModel.png')\n",
        "SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"556pt\" viewBox=\"0.00 0.00 234.00 556.00\" width=\"234pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 230,-552 230,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139644717343632 -->\n<g class=\"node\" id=\"node1\">\n<title>139644717343632</title>\n<polygon fill=\"none\" points=\"46.5,-511.5 46.5,-547.5 179.5,-547.5 179.5,-511.5 46.5,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-525.8\">input_2: InputLayer</text>\n</g>\n<!-- 139644717344752 -->\n<g class=\"node\" id=\"node2\">\n<title>139644717344752</title>\n<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 226,-474.5 226,-438.5 0,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-452.8\">zero_padding2d_2: ZeroPadding2D</text>\n</g>\n<!-- 139644717343632&#45;&gt;139644717344752 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139644717343632-&gt;139644717344752</title>\n<path d=\"M113,-511.4551C113,-503.3828 113,-493.6764 113,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-484.5903 113,-474.5904 109.5001,-484.5904 116.5001,-484.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139644717344808 -->\n<g class=\"node\" id=\"node3\">\n<title>139644717344808</title>\n<polygon fill=\"none\" points=\"58,-365.5 58,-401.5 168,-401.5 168,-365.5 58,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-379.8\">conv0: Conv2D</text>\n</g>\n<!-- 139644717344752&#45;&gt;139644717344808 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139644717344752-&gt;139644717344808</title>\n<path d=\"M113,-438.4551C113,-430.3828 113,-420.6764 113,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-411.5903 113,-401.5904 109.5001,-411.5904 116.5001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139644717345088 -->\n<g class=\"node\" id=\"node4\">\n<title>139644717345088</title>\n<polygon fill=\"none\" points=\"32.5,-292.5 32.5,-328.5 193.5,-328.5 193.5,-292.5 32.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-306.8\">bn0: BatchNormalization</text>\n</g>\n<!-- 139644717344808&#45;&gt;139644717345088 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139644717344808-&gt;139644717345088</title>\n<path d=\"M113,-365.4551C113,-357.3828 113,-347.6764 113,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-338.5903 113,-328.5904 109.5001,-338.5904 116.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139644717345928 -->\n<g class=\"node\" id=\"node5\">\n<title>139644717345928</title>\n<polygon fill=\"none\" points=\"36,-219.5 36,-255.5 190,-255.5 190,-219.5 36,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-233.8\">activation_2: Activation</text>\n</g>\n<!-- 139644717345088&#45;&gt;139644717345928 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139644717345088-&gt;139644717345928</title>\n<path d=\"M113,-292.4551C113,-284.3828 113,-274.6764 113,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-265.5903 113,-255.5904 109.5001,-265.5904 116.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139644734816720 -->\n<g class=\"node\" id=\"node6\">\n<title>139644734816720</title>\n<polygon fill=\"none\" points=\"26.5,-146.5 26.5,-182.5 199.5,-182.5 199.5,-146.5 26.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-160.8\">max_pool: MaxPooling2D</text>\n</g>\n<!-- 139644717345928&#45;&gt;139644734816720 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139644717345928-&gt;139644734816720</title>\n<path d=\"M113,-219.4551C113,-211.3828 113,-201.6764 113,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-192.5903 113,-182.5904 109.5001,-192.5904 116.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139645019377736 -->\n<g class=\"node\" id=\"node7\">\n<title>139645019377736</title>\n<polygon fill=\"none\" points=\"56.5,-73.5 56.5,-109.5 169.5,-109.5 169.5,-73.5 56.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-87.8\">flatten_2: Flatten</text>\n</g>\n<!-- 139644734816720&#45;&gt;139645019377736 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139644734816720-&gt;139645019377736</title>\n<path d=\"M113,-146.4551C113,-138.3828 113,-128.6764 113,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-119.5903 113,-109.5904 109.5001,-119.5904 116.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 139644717338864 -->\n<g class=\"node\" id=\"node8\">\n<title>139644717338864</title>\n<polygon fill=\"none\" points=\"78,-.5 78,-36.5 148,-36.5 148,-.5 78,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-14.8\">fc: Dense</text>\n</g>\n<!-- 139645019377736&#45;&gt;139644717338864 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139645019377736-&gt;139644717338864</title>\n<path d=\"M113,-73.4551C113,-65.3828 113,-55.6764 113,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"116.5001,-46.5903 113,-36.5904 109.5001,-46.5904 116.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}